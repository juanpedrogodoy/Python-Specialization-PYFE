# Python for Everybody (PY4E) - My Learning Journey üöÄ

Welcome to my Python learning repository! Here I document my progress through the "Python for Everybody" Specialization. This repo contains not only the course solutions but also my personal evolution as a programmer, including extra challenges requested from AI to reinforce my logic.

---

## üìÇ Project Structure

### [Module 01: Python Fundamentals]
Focused on basic syntax, control flow, and initial logic.
* **01_hello_world.py**: My first bilingual script.
* **02_overtime_pay.py**: Using `if/else` conditionals for labor calculations.
* **03_grade_score_calculator.py**: Grade classification using `elif`.
* **04_computepay_function.py**: Introduction to functions and return values.
* **05_largest_and_smallest.py**: Mastery of `while` loops and `None` values.

#### üìÇ extras (Inside Module 01)
* **multi_currency_budgeter.py**: üèÜ **Final Boss** - A complete currency converter integrating functions, loops, and error handling.
* **logic_tools_collection.py**: A collection of extra logic challenges (leap years, discounts, etc.) generated by AI to deepen my understanding.

---

### [Module 02: Data Structures]
The focus shifted towards external data manipulation and complex structures.
* **01_string_parsing.py**: Extracting numerical data from text strings using slicing.
* **02_files_shout.py**: External file reading and line-by-line text processing.
* **03_spam_confidence_average.py**: Data filtering and statistical calculations from `.txt` files.
* **04_unique_words_list.py**: Using nested loops to build a sorted list of unique words.
* **05_email_parser.py**: Mass extraction of senders using list indexing.
* **06_most_prolific_sender.py**: Implementing histograms with **Dictionaries** to find maximum frequencies.
* **07_hourly_email_distribution.py**: üèÅ **Module Capstone** - Analyzing hourly distribution by combining Dictionaries and **Tuples** for sorting.

---

## üõ†Ô∏è Tools & Methodology
* **Language:** Python 3.x
* **Learning Style:** Active learning. Every exercise was solved independently. For extra challenges, I used AI to generate the problem statement and then validated my logic through my own resolution.
* **Transparency:** Codes and comments reflect a real learning process.

---

## üí° Next Steps
Currently moving towards **Module 03: Accessing Web Data**, where I will learn about Web Scraping, JSON, and XML APIs.
